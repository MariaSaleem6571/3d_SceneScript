{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Point Cloud Encoder**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " *Importing Libraries*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import open3d as o3d\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "import os\n",
    "import torchsparse\n",
    "from code_snippets.readers import read_points_file\n",
    "from torch import nn\n",
    "import torchsparse.nn as spnn\n",
    "import torchsparse.nn.functional as F\n",
    "import torchsparse.utils as sp_utils\n",
    "from torchsparse import SparseTensor\n",
    "from torchsparse.utils.quantize import sparse_quantize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " *Initializing the Point Clouds Data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_points_file(filepath):\n",
    "    assert os.path.exists(filepath), f\"Could not find point cloud file: {filepath}\"\n",
    "    df = pd.read_csv(filepath, compression=\"gzip\")\n",
    "    point_cloud = df[[\"px_world\", \"py_world\", \"pz_world\"]]\n",
    "    dist_std = df[\"dist_std\"]\n",
    "    # print(f\"Loaded point cloud with {len(point_cloud)} points.\")\n",
    "    return point_cloud.to_numpy(), dist_std.to_numpy()\n",
    "\n",
    "points, dist_std = read_points_file(\"/home/mseleem/Desktop/3d_model_pt/0/semidense_points.csv.gz\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " *Voxelize Point Clouds*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(points)\n",
    "voxel_size = 0.015  # 1.5cm\n",
    "voxel_grid = o3d.geometry.VoxelGrid.create_from_point_cloud(pcd, voxel_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of points: 433426\n",
      "Number of voxels: 331598\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of points: {len(np.asarray(pcd.points))}\")\n",
    "print(\"Number of voxels:\", len(voxel_grid.get_voxels()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Visualize*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] GLFW Error: X11: The DISPLAY environment variable is missing\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] Failed to initialize GLFW\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] [DrawGeometries] Failed creating OpenGL window.\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "o3d.visualization.draw_geometries([voxel_grid])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Konsa point kis voxel mein hai? or baad mein debugging checks hain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxel_map = {}\n",
    "\n",
    "for i, point in enumerate(points):\n",
    "    voxel_index = tuple(voxel_grid.get_voxel(point))\n",
    "    if voxel_index in voxel_map:\n",
    "        voxel_map[voxel_index].append(i)\n",
    "    else:\n",
    "        voxel_map[voxel_index] = [i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for empty voxels\n",
    "empty_voxels = [k for k, v in voxel_map.items() if len(v) == 0]\n",
    "assert len(empty_voxels) == 0, \"There are empty voxels in the mapping!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total points in voxels: 433426\n",
      "Total original points: 433426\n"
     ]
    }
   ],
   "source": [
    "# Check total points\n",
    "total_points_in_voxels = sum(len(v) for v in voxel_map.values())\n",
    "print(f\"Total points in voxels: {total_points_in_voxels}\")\n",
    "print(f\"Total original points: {len(points)}\")\n",
    "assert total_points_in_voxels == len(points), f\"Mismatch in point counts: {total_points_in_voxels} != {len(points)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voxel index: (1014, 611, 579), Point indices: [20]\n",
      "Voxel index: (1017, 610, 580), Point indices: [21]\n",
      "Voxel index: (1042, 594, 579), Point indices: [22, 1482]\n",
      "Voxel index: (984, 621, 427), Point indices: [23, 259852]\n",
      "Voxel index: (984, 622, 426), Point indices: [24]\n",
      "Voxel index: (1007, 620, 588), Point indices: [25]\n",
      "Voxel index: (982, 625, 419), Point indices: [26, 1489, 80391, 254305]\n",
      "Voxel index: (993, 621, 420), Point indices: [27]\n",
      "Voxel index: (974, 630, 418), Point indices: [28]\n",
      "Voxel index: (995, 621, 418), Point indices: [29]\n"
     ]
    }
   ],
   "source": [
    "# Print a few voxel mappings for verification\n",
    "for k, v in list(voxel_map.items())[20:30]:\n",
    "    print(f\"Voxel index: {k}, Point indices: {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Aggregated features for sample voxels (indices 20 to 30):\n",
      "Voxel index: (1014, 611, 579), Aggregated feature: 0.0207\n",
      "Voxel index: (1017, 610, 580), Aggregated feature: 0.0214\n",
      "Voxel index: (1042, 594, 579), Aggregated feature: 0.0264\n",
      "Voxel index: (984, 621, 427), Aggregated feature: 0.0036\n",
      "Voxel index: (984, 622, 426), Aggregated feature: 0.0054\n",
      "Voxel index: (1007, 620, 588), Aggregated feature: 0.0248\n",
      "Voxel index: (982, 625, 419), Aggregated feature: 0.0058\n",
      "Voxel index: (993, 621, 420), Aggregated feature: 0.0099\n",
      "Voxel index: (974, 630, 418), Aggregated feature: 0.0052\n",
      "Voxel index: (995, 621, 418), Aggregated feature: 0.0106\n"
     ]
    }
   ],
   "source": [
    "# Aggregate features for each voxel, print aggregated features for sample voxels, and convert to tensors\n",
    "aggregated_features = []\n",
    "filtered_voxel_indices = []\n",
    "print(\"\\nAggregated features for sample voxels (indices 20 to 30):\")\n",
    "for idx, (voxel_index, point_indices) in enumerate(voxel_map.items()):\n",
    "    aggregated_feature = np.mean(dist_std[point_indices])  # Example aggregation: mean\n",
    "    aggregated_features.append(aggregated_feature)\n",
    "    filtered_voxel_indices.append(voxel_index)\n",
    "    \n",
    "    # Print the aggregated feature for voxels with indices 20 to 30\n",
    "    if 20 <= idx < 30:\n",
    "        print(f\"Voxel index: {voxel_index}, Aggregated feature: {aggregated_feature:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voxel indices tensor dimensions: torch.Size([331598, 3])\n",
      "Features tensor dimensions: torch.Size([331598, 1])\n"
     ]
    }
   ],
   "source": [
    "voxel_indices_tensor = torch.tensor(filtered_voxel_indices, dtype=torch.int32).cuda()\n",
    "features_tensor = torch.tensor(aggregated_features, dtype=torch.float32).view(-1, 1).cuda()\n",
    "\n",
    "print(f\"Voxel indices tensor dimensions: {voxel_indices_tensor.shape}\")\n",
    "print(f\"Features tensor dimensions: {features_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add batch dimension to voxel indices\n",
    "batch_indices = torch.zeros((voxel_indices_tensor.shape[0], 1), dtype=torch.int32).cuda()\n",
    "voxel_indices_tensor_with_batch = torch.cat([batch_indices, voxel_indices_tensor], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse tensor feature dimensions: torch.Size([331598, 1])\n",
      "Sparse tensor coordinate dimensions: torch.Size([331598, 4])\n"
     ]
    }
   ],
   "source": [
    "# Create sparse tensor\n",
    "sparse_tensor = SparseTensor(features_tensor, voxel_indices_tensor_with_batch)\n",
    "\n",
    "print(f\"Sparse tensor feature dimensions: {sparse_tensor.F.shape}\")\n",
    "print(f\"Sparse tensor coordinate dimensions: {sparse_tensor.C.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseResNetEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SparseResNetEncoder, self).__init__()\n",
    "        self.conv1 = spnn.Conv3d(1, 16, kernel_size=3, stride=2)\n",
    "        self.conv2 = spnn.Conv3d(16, 32, kernel_size=3, stride=2)\n",
    "        self.conv3 = spnn.Conv3d(32, 64, kernel_size=3, stride=2)\n",
    "        self.conv4 = spnn.Conv3d(64, 128, kernel_size=3, stride=2)\n",
    "        self.conv5 = spnn.Conv3d(128, 512, kernel_size=3, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(f\"Input to conv1: {x.F.shape}, {x.C.shape}\")\n",
    "        x = self.conv1(x)\n",
    "        print(f\"Output of conv1: {x.F.shape}, {x.C.shape}\")\n",
    "        x = self.conv2(x)\n",
    "        print(f\"Output of conv2: {x.F.shape}, {x.C.shape}\")\n",
    "        x = self.conv3(x)\n",
    "        print(f\"Output of conv3: {x.F.shape}, {x.C.shape}\")\n",
    "        x = self.conv4(x)\n",
    "        print(f\"Output of conv4: {x.F.shape}, {x.C.shape}\")\n",
    "        x = self.conv5(x)\n",
    "        print(f\"Output of conv5: {x.F.shape}, {x.C.shape}\")\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input to conv1: torch.Size([331598, 1]), torch.Size([331598, 4])\n",
      "Output of conv1: torch.Size([473947, 16]), torch.Size([473947, 4])\n",
      "Output of conv2: torch.Size([224334, 32]), torch.Size([224334, 4])\n",
      "Output of conv3: torch.Size([78220, 64]), torch.Size([78220, 4])\n",
      "Output of conv4: torch.Size([21792, 128]), torch.Size([21792, 4])\n",
      "Output of conv5: torch.Size([5168, 512]), torch.Size([5168, 4])\n",
      "Encoded coordinates before removing batch dimension:\n",
      "tensor([[ 0.,  0., 11., 15.],\n",
      "        [ 0.,  0., 11., 16.],\n",
      "        [ 0.,  0., 12., 15.],\n",
      "        [ 0.,  0., 12., 16.],\n",
      "        [ 0.,  8.,  4., 15.],\n",
      "        [ 0.,  8.,  4., 16.],\n",
      "        [ 0.,  8.,  4., 17.],\n",
      "        [ 0.,  8.,  4., 18.],\n",
      "        [ 0.,  8.,  5., 15.],\n",
      "        [ 0.,  8.,  5., 16.]], device='cuda:0')\n",
      "Encoded coordinates after removing batch dimension:\n",
      "tensor([[ 0., 11., 15.],\n",
      "        [ 0., 11., 16.],\n",
      "        [ 0., 12., 15.],\n",
      "        [ 0., 12., 16.],\n",
      "        [ 8.,  4., 15.],\n",
      "        [ 8.,  4., 16.],\n",
      "        [ 8.,  4., 17.],\n",
      "        [ 8.,  4., 18.],\n",
      "        [ 8.,  5., 15.],\n",
      "        [ 8.,  5., 16.]], device='cuda:0')\n",
      "Encoded features with positional encoding:\n",
      "tensor([[ 2.4048e-06, -2.2362e-07,  4.8957e-07,  ...,  0.0000e+00,\n",
      "          1.1000e+01,  1.5000e+01],\n",
      "        [-1.3749e-06, -6.6866e-07,  8.0236e-07,  ...,  0.0000e+00,\n",
      "          1.1000e+01,  1.6000e+01],\n",
      "        [ 2.7204e-06,  5.3744e-06,  1.1922e-05,  ...,  0.0000e+00,\n",
      "          1.2000e+01,  1.5000e+01],\n",
      "        ...,\n",
      "        [ 1.3912e-06,  5.8117e-07, -1.1010e-06,  ...,  8.0000e+00,\n",
      "          4.0000e+00,  1.8000e+01],\n",
      "        [ 5.5792e-08, -3.3315e-06,  1.2814e-06,  ...,  8.0000e+00,\n",
      "          5.0000e+00,  1.5000e+01],\n",
      "        [ 2.7806e-07, -4.0906e-06,  2.2773e-06,  ...,  8.0000e+00,\n",
      "          5.0000e+00,  1.6000e+01]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Coordinates as numpy array:\n",
      "[[ 0. 11. 15.]\n",
      " [ 0. 11. 16.]\n",
      " [ 0. 12. 15.]\n",
      " [ 0. 12. 16.]\n",
      " [ 8.  4. 15.]\n",
      " [ 8.  4. 16.]\n",
      " [ 8.  4. 17.]\n",
      " [ 8.  4. 18.]\n",
      " [ 8.  5. 15.]\n",
      " [ 8.  5. 16.]]\n",
      "Sorted indices (numpy):\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "Sorted indices (PyTorch):\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], device='cuda:0')\n",
      "Encoded and sorted features with positional encoding:\n",
      "torch.Size([5168, 515])\n",
      "tensor([[ 2.4048e-06, -2.2362e-07,  4.8957e-07,  ...,  0.0000e+00,\n",
      "          1.1000e+01,  1.5000e+01],\n",
      "        [-1.3749e-06, -6.6866e-07,  8.0236e-07,  ...,  0.0000e+00,\n",
      "          1.1000e+01,  1.6000e+01],\n",
      "        [ 2.7204e-06,  5.3744e-06,  1.1922e-05,  ...,  0.0000e+00,\n",
      "          1.2000e+01,  1.5000e+01],\n",
      "        ...,\n",
      "        [ 1.3912e-06,  5.8117e-07, -1.1010e-06,  ...,  8.0000e+00,\n",
      "          4.0000e+00,  1.8000e+01],\n",
      "        [ 5.5792e-08, -3.3315e-06,  1.2814e-06,  ...,  8.0000e+00,\n",
      "          5.0000e+00,  1.5000e+01],\n",
      "        [ 2.7806e-07, -4.0906e-06,  2.2773e-06,  ...,  8.0000e+00,\n",
      "          5.0000e+00,  1.6000e+01]], device='cuda:0', grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "encoder = SparseResNetEncoder().cuda()\n",
    "encoded_features = encoder(sparse_tensor.cuda())\n",
    "encoded_coordinates = encoded_features.C.float().cuda()\n",
    "\n",
    "print(\"Encoded coordinates before removing batch dimension:\")\n",
    "print(encoded_coordinates[:10])  \n",
    "\n",
    "# Remove the batch dimension\n",
    "encoded_coordinates = encoded_coordinates[:, 1:]\n",
    "\n",
    "print(\"Encoded coordinates after removing batch dimension:\")\n",
    "print(encoded_coordinates[:10]) \n",
    "\n",
    "# Concatenate encoded features with positional encoding\n",
    "encoded_features_with_pos = torch.cat([encoded_features.F, encoded_coordinates], dim=1)\n",
    "\n",
    "print(\"Encoded features with positional encoding:\")\n",
    "print(encoded_features_with_pos[:10]) \n",
    "\n",
    "# Convert to numpy array for sorting\n",
    "coordinates_np = encoded_coordinates.cpu().numpy()\n",
    "\n",
    "print(\"Coordinates as numpy array:\")\n",
    "print(coordinates_np[:10])  \n",
    "\n",
    "# Perform lexicographical sort: x-coordinate, then y-coordinate, then z-coordinate\n",
    "sorted_indices_np = np.lexsort((coordinates_np[:, 2], coordinates_np[:, 1], coordinates_np[:, 0]))\n",
    "\n",
    "print(\"Sorted indices (numpy):\")\n",
    "print(sorted_indices_np[:10])  \n",
    "\n",
    "# Convert sorted indices back to PyTorch tensor\n",
    "sorted_indices = torch.from_numpy(sorted_indices_np).long().cuda()\n",
    "\n",
    "print(\"Sorted indices (PyTorch):\")\n",
    "print(sorted_indices[:10])  \n",
    "\n",
    "# Apply sorted indices to the features with positional encoding\n",
    "sorted_features_with_pos = encoded_features_with_pos[sorted_indices]\n",
    "\n",
    "print(\"Encoded and sorted features with positional encoding:\")\n",
    "print(sorted_features_with_pos.shape)\n",
    "print(sorted_features_with_pos[:10])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize the model\n",
    "# encoder = SparseResNetEncoder().cuda()\n",
    "\n",
    "# # Forward pass\n",
    "# encoded_features = encoder(sparse_tensor.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Append coordinates to feature vectors for positional encoding\n",
    "# encoded_coordinates = encoded_features.C.float().cuda()\n",
    "\n",
    "# # Check the shapes of encoded_features.F and coordinates\n",
    "# print(f\"Shape of encoded_features.F: {encoded_features.F.shape}\")\n",
    "# print(f\"Shape of coordinates.C: {encoded_coordinates.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded_coordinates = encoded_coordinates[:, 1:] # Remove batch dimension\n",
    "# # print(encoded_coordinates.shape)\n",
    "# print(encoded_coordinates[1:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Concatenate the features with the coordinates along the feature dimension\n",
    "# encoded_features_with_pos = torch.cat([encoded_features.F, encoded_coordinates], dim=1)\n",
    "\n",
    "# print(encoded_features_with_pos.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sort the feature vectors lexicographically by coordinates using numpy\n",
    "# coordinates_np = encoded_coordinates.cpu().numpy()\n",
    "# sorted_indices_np = np.lexsort((coordinates_np[:, 2], coordinates_np[:, 1], coordinates_np[:, 0]))\n",
    "# sorted_indices = torch.from_numpy(sorted_indices_np).long().cuda()\n",
    "\n",
    "# # Apply sorting to the concatenated features\n",
    "# sorted_features_with_pos = encoded_features_with_pos[sorted_indices]\n",
    "\n",
    "# # Print the encoded and sorted features with positional encoding\n",
    "# print(\"Encoded and sorted features with positional encoding:\")\n",
    "# print(sorted_features_with_pos.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
