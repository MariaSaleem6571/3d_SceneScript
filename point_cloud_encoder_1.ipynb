{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Point Cloud Encoder**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " *Importing Libraries*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import torch\n",
    "import open3d as o3d\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "import os\n",
    "from code_snippets.readers import read_points_file\n",
    "from itertools import product\n",
    "import torchsparse\n",
    "from torch import nn\n",
    "import torchsparse.nn as spnn\n",
    "import torchsparse.nn.functional as F\n",
    "import torchsparse.utils as sp_utils\n",
    "from torchsparse import SparseTensor\n",
    "from torchsparse.utils.quantize import sparse_quantize\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " *Initializing the Point Clouds Data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded point cloud with 433426 points.\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "def read_points_file(filepath):\n",
    "    assert os.path.exists(filepath), f\"Could not find point cloud file: {filepath}\"\n",
    "    df = pd.read_csv(filepath, compression=\"gzip\")\n",
    "    point_cloud = df[[\"px_world\", \"py_world\", \"pz_world\"]]\n",
    "    dist_std = df[\"dist_std\"]\n",
    "    print(f\"Loaded point cloud with {len(point_cloud)} points.\")\n",
    "    return point_cloud.to_numpy(), dist_std.to_numpy()\n",
    "\n",
    "# Example usage\n",
    "points, dist_std = read_points_file(\"/home/mseleem/Desktop/3d_model_pt/0/semidense_points.csv.gz\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " *Voxelize Point Clouds*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of points: 433426\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "num_points = len(pcd.points)\n",
    "print(f\"Number of points: {num_points}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "voxel_size = 0.015  # 1.5cm\n",
    "voxel_grid = o3d.geometry.VoxelGrid.create_from_point_cloud(pcd, voxel_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of voxels: 331598\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "print(\"Number of voxels:\", len(voxel_grid.get_voxels()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "o3d.visualization.draw_geometries([voxel_grid])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Initialize a dictionary to map voxel indices to point indices\n",
    "voxel_map = {}\n",
    "\n",
    "# Map points to their respective voxels\n",
    "for i, point in enumerate(points):\n",
    "    voxel_index = tuple(voxel_grid.get_voxel(point))\n",
    "    if voxel_index in voxel_map:\n",
    "        voxel_map[voxel_index].append(i)\n",
    "    else:\n",
    "        voxel_map[voxel_index] = [i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All voxels have associated points.\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Check for empty voxels\n",
    "empty_voxels = [k for k, v in voxel_map.items() if len(v) == 0]\n",
    "assert len(empty_voxels) == 0, \"There are empty voxels in the mapping!\"\n",
    "print(\"All voxels have associated points.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total points in voxels: 433426\n",
      "Total original points: 433426\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Check total points\n",
    "total_points_in_voxels = sum(len(v) for v in voxel_map.values())\n",
    "print(f\"Total points in voxels: {total_points_in_voxels}\")\n",
    "print(f\"Total original points: {len(points)}\")\n",
    "assert total_points_in_voxels == len(points), f\"Mismatch in point counts: {total_points_in_voxels} != {len(points)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Aggregate features for each voxel\n",
    "aggregated_features = []\n",
    "filtered_voxel_indices = []\n",
    "for voxel_index, point_indices in voxel_map.items():\n",
    "    aggregated_feature = np.mean(dist_std[point_indices])  # Example aggregation: mean\n",
    "    aggregated_features.append(aggregated_feature)\n",
    "    filtered_voxel_indices.append(voxel_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample voxel mappings (first 10):\n",
      "Voxel index: (933, 623, 427), Point indices: [0, 268155]\n",
      "Voxel index: (969, 567, 399), Point indices: [1]\n",
      "Voxel index: (977, 571, 403), Point indices: [2]\n",
      "Voxel index: (1003, 533, 396), Point indices: [3]\n",
      "Voxel index: (1006, 534, 400), Point indices: [4]\n",
      "Voxel index: (955, 620, 440), Point indices: [5]\n",
      "Voxel index: (961, 611, 428), Point indices: [6]\n",
      "Voxel index: (994, 564, 410), Point indices: [7]\n",
      "Voxel index: (988, 577, 591), Point indices: [8]\n",
      "Voxel index: (968, 611, 428), Point indices: [9]\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Print a few voxel mappings for verification\n",
    "print(\"Sample voxel mappings (first 10):\")\n",
    "for k, v in list(voxel_map.items())[:10]:\n",
    "    print(f\"Voxel index: {k}, Point indices: {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Aggregated features for sample voxels (first 10):\n",
      "Voxel index: (933, 623, 427), Aggregated feature: 0.0022\n",
      "Voxel index: (969, 567, 399), Aggregated feature: 0.0140\n",
      "Voxel index: (977, 571, 403), Aggregated feature: 0.0179\n",
      "Voxel index: (1003, 533, 396), Aggregated feature: 0.0358\n",
      "Voxel index: (1006, 534, 400), Aggregated feature: 0.0357\n",
      "Voxel index: (955, 620, 440), Aggregated feature: 0.0023\n",
      "Voxel index: (961, 611, 428), Aggregated feature: 0.0040\n",
      "Voxel index: (994, 564, 410), Aggregated feature: 0.0155\n",
      "Voxel index: (988, 577, 591), Aggregated feature: 0.0350\n",
      "Voxel index: (968, 611, 428), Aggregated feature: 0.0044\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Verify feature aggregation for a few voxels\n",
    "print(\"\\nAggregated features for sample voxels (first 10):\")\n",
    "aggregated_features = []\n",
    "filtered_voxel_indices = []\n",
    "for voxel_index, point_indices in list(voxel_map.items())[:10]:  # Check first 10 voxels\n",
    "    aggregated_feature = np.mean(dist_std[point_indices])  # Example aggregation: mean\n",
    "    print(f\"Voxel index: {voxel_index}, Aggregated feature: {aggregated_feature:.4f}\")\n",
    "    aggregated_features.append(aggregated_feature)\n",
    "    filtered_voxel_indices.append(voxel_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Convert to tensor (for the full dataset)\n",
    "all_aggregated_features = []\n",
    "all_filtered_voxel_indices = []\n",
    "for voxel_index, point_indices in voxel_map.items():\n",
    "    aggregated_feature = np.mean(dist_std[point_indices])\n",
    "    all_aggregated_features.append(aggregated_feature)\n",
    "    all_filtered_voxel_indices.append(voxel_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Convert to tensor\n",
    "voxel_indices_tensor = torch.tensor(all_filtered_voxel_indices, dtype=torch.int32)\n",
    "features_tensor = torch.tensor(all_aggregated_features, dtype=torch.float32).view(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Add batch dimension to voxel indices\n",
    "batch_indices = torch.zeros((voxel_indices_tensor.shape[0], 1), dtype=torch.int32)\n",
    "voxel_indices_tensor_with_batch = torch.cat([batch_indices, voxel_indices_tensor], dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voxel indices tensor dimensions: torch.Size([331598, 4])\n",
      "Features tensor dimensions: torch.Size([331598, 1])\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Print dimensions of the tensors\n",
    "print(f\"Voxel indices tensor dimensions: {voxel_indices_tensor_with_batch.shape}\")\n",
    "print(f\"Features tensor dimensions: {features_tensor.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse tensor feature dimensions: torch.Size([331598, 1])\n",
      "Sparse tensor coordinate dimensions: torch.Size([331598, 4])\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Create sparse tensor\n",
    "sparse_tensor = SparseTensor(features_tensor, voxel_indices_tensor_with_batch)\n",
    "\n",
    "# Print dimensions of the sparse tensor\n",
    "print(f\"Sparse tensor feature dimensions: {sparse_tensor.F.shape}\")\n",
    "print(f\"Sparse tensor coordinate dimensions: {sparse_tensor.C.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "class SparseResNetEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SparseResNetEncoder, self).__init__()\n",
    "        self.conv1 = spnn.Conv3d(1, 16, kernel_size=3, stride=2)\n",
    "        self.conv2 = spnn.Conv3d(16, 32, kernel_size=3, stride=2)\n",
    "        self.conv3 = spnn.Conv3d(32, 64, kernel_size=3, stride=2)\n",
    "        self.conv4 = spnn.Conv3d(64, 128, kernel_size=3, stride=2)\n",
    "        self.conv5 = spnn.Conv3d(128, 512, kernel_size=3, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(f\"Input to conv1: {x.F.shape}, {x.C.shape}\")\n",
    "        x = self.conv1(x)\n",
    "        print(f\"Output of conv1: {x.F.shape}, {x.C.shape}\")\n",
    "        x = self.conv2(x)\n",
    "        print(f\"Output of conv2: {x.F.shape}, {x.C.shape}\")\n",
    "        x = self.conv3(x)\n",
    "        print(f\"Output of conv3: {x.F.shape}, {x.C.shape}\")\n",
    "        x = self.conv4(x)\n",
    "        print(f\"Output of conv4: {x.F.shape}, {x.C.shape}\")\n",
    "        x = self.conv5(x)\n",
    "        print(f\"Output of conv5: {x.F.shape}, {x.C.shape}\")\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input to conv1: torch.Size([331598, 1]), torch.Size([331598, 4])\n",
      "RuntimeError during encoder forward pass: \n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Initialize the model\n",
    "encoder = SparseResNetEncoder()\n",
    "\n",
    "# Forward pass\n",
    "encoded_features = encoder(sparse_tensor)\n",
    "\n",
    "\n",
    "# Append coordinates to feature vectors for positional encoding\n",
    "# coordinates = sparse_tensor.C.float()\n",
    "# encoded_features_with_pos = torch.cat([encoded_features.F, coordinates], dim=1)\n",
    "\n",
    "# Sort the feature vectors lexicographically by coordinates\n",
    "# sorted_indices = torch.lexsort((coordinates[:, 2], coordinates[:, 1], coordinates[:, 0]))\n",
    "# sorted_features_with_pos = encoded_features_with_pos[sorted_indices]\n",
    "\n",
    "# print(\"Encoded and sorted features with positional encoding:\")\n",
    "# print(sorted_features_with_pos)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
